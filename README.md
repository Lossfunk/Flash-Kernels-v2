# Flash-Kernels v2 â€“ Quick Reference

A lean playground for experimenting with **Triton** GPU kernels.

Directory highlights
1. `benchmarks/` â€“ micro-benchmarks + visualisations
2. `new_kernels/` â€“ hand-tuned Triton ops (LayerNorm, Softmax, â€¦)
3. `evals/` â€“ PyTest correctness & regression suite
4. `agents/` â€“ LLM pipeline that auto-writes kernels for KernelBench

---
## 1 Â· Installation
```bash
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt      # Triton â‰¥2,<3 + plotting + agent deps
```
GPU prerequisites
* CUDA 11.8+ drivers
* Compute Capability â‰¥ 7.0 (RTX 30-series, A100/H100, â€¦)

---
## 2 Â· Running the tests (`evals/`)
```bash
pytest -q evals       # FP32 + BF16 when supported
```
Tests compare the Triton kernels against the PyTorch reference with strict
`assert_verbose_allclose` tolerances.

---
## 3 Â· Benchmarking (`benchmarks/`)
### 3.1  One-liner drivers  ðŸš€
For the common cases you do **not** need to pass any arguments â€“ just execute
one of the convenience shell scripts and grab a coffee:
```bash
# Forward-only roofline runs
bash benchmarks/run_layer_norm_sol.sh
bash benchmarks/run_softmax_sol.sh
bash benchmarks/run_diagonal_matmul_sol.sh
bash benchmarks/run_fused_linear_rowsum_sol.sh
```
Each script will
1. call the corresponding `benchmarks/scripts/benchmark_*.py` file,
2. append results to `benchmarks/data/all_benchmark_data.csv`,
3. auto-generate PNGs in `benchmarks/visualizations/` (one per extra-config).

### 3.2  Manual control
Prefer explicit flags?  You can run the python scripts directly:
```bash
python benchmarks/scripts/benchmark_layer_norm.py --overwrite
python benchmarks/benchmark_visualizer.py \
       --kernel-name layer_norm --metric-name speed \
       --kernel-operation-mode forward --display
```
âš ï¸  *The visualiser iterates over every unique `extra_benchmark_config` unless
`--extra-config-filter` is supplied.*  Expect several PNGs.

---
## 4 Â· Reproducing the paper numbers
Full-scale regeneration (~25 min on an H100):
```bash
source venv/bin/activate  # ensure deps are present
for s in benchmarks/scripts/benchmark_*.py; do python "$s" --overwrite; done
for k in fused_linear_rowsum layer_norm softmax diag_matmul; do
  python benchmarks/benchmark_visualizer.py --kernel-name "$k" --metric-name speed
  python benchmarks/benchmark_visualizer.py --kernel-name "$k" --metric-name memory || true
done
```
Hardware: Ampere or newer GPU with â‰¥40 GB VRAM to cover the largest cases.
Generated `all_benchmark_data.csv` should match the committed copy (timestamps differ).
